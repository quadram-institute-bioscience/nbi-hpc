---
title: "Bioinformatics packages"
---

## The dependency problem

In bioinformatics, we rely on a rich ecosystem of tools: **samtools** for BAM files, **minimap2** for alignment, **kraken2** for taxonomic classification, and dozens more. Each tool is a piece of software with its own requirements — specific libraries, compilers, or other tools it depends on.

Here's where things get tricky. 
*Tool A* might need Python 3.8 and a specific version of `libhts`, while *Tool B* requires Python 3.11 and a *different* version of the same library. Install both system-wide, and you have a **conflict**: they can't coexist peacefully.

It gets worse. 
Your colleague runs a pipeline that worked perfectly six months ago, but now it fails. Why? Because a dependency was updated, and the new version behaves differently. Or you need to run **Kraken2 v2.0.8** for one project (to match published results) and **v2.1.3** for another. Managing multiple versions of the same tool on a single system is a nightmare.

This is the **dependency hell** that every bioinformatician eventually faces: conflicting requirements, version mismatches, and the dreaded "it works on my machine" problem.

## A solution: Conda

> Here we use "Conda" as a name for the technology, while we will use a similar tool called Micromamba

**Conda** is a package and environment manager that elegantly solves many of these problems. The key insight is *isolation*: instead of installing everything system-wide, Conda creates self-contained **environments**.

Each environment is like a bubble: it has its own set of packages, its own versions, completely independent from other environments. You can have one environment with Python 3.8 and samtools 1.15, another with Python 3.11 and samtools 1.17, and switch between them in seconds.

Conda also handles dependencies automatically. When you ask for a tool, Conda figures out what else is needed, checks for conflicts, and installs a compatible set of packages. No more manual hunting for libraries.

The **Bioconda** channel extends this to bioinformatics, offering thousands of pre-built packages ready to install. Need kraken2? One command. Need BLAST? One command. The community maintains recipes, so you don't have to compile from source.

This approach has transformed reproducibility: share your environment file, and anyone can recreate your exact setup.

## Another solution: Containers

Containers take isolation to the next level. While Conda isolates packages, a **container** isolates the *entire operating system environment* — libraries, tools, configurations, everything.

Think of a container as a lightweight virtual machine (though technically it's not). Inside the container, your tool sees a complete Linux system exactly as the developer intended. Outside, it's just a single file you can move around.

**Docker** popularised containers and remains the standard in cloud computing. However, Docker requires root privileges to run, which is a security concern on shared systems like HPCs.

**Singularity** (now also known as **Apptainer**) was designed specifically for HPC environments. It runs containers without root access, integrates naturally with job schedulers like Slurm, and can even convert Docker images. This makes it the go-to solution for running containerised bioinformatics tools on clusters.

The beauty of containers is *absolute reproducibility*: the container that worked today will work identically in five years, on any system that can run Singularity.

## Conda vs Singularity

Both Conda and Singularity solve the dependency problem, but they have different strengths.

**Conda** is incredibly user-friendly. Creating environments, installing packages, and switching between them takes seconds. It's perfect for exploratory work, testing new tools, or when you need flexibility. However, Conda environments can become fragile over time — a channel update might break your setup, and complex environments sometimes develop subtle conflicts.

**Singularity containers** offer stronger guarantees. A container is a frozen snapshot: it won't change unless you explicitly rebuild it. This makes containers ideal for production pipelines and published workflows. The downside is that building containers requires more effort, and you can't easily "add one more package" like you would with Conda.

### A software catalogue

On a shared HPC, there's another consideration: **managed software**. When hundreds of users each install their own Conda environments, storage bloats and support becomes impossible. A curated archive of Singularity containers, tested and maintained by the HPC team, ensures everyone has access to reliable, optimised tools.

At the NBI HPC, we use **Singularity** to package our tools and **LMOD** as the software catalogue. LMOD provides a simple `module load` interface to access containerised tools — you get the reproducibility of containers with the convenience of a well-organised library. We'll see how this works in practice in the next sections.